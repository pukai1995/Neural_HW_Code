{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3fc93d99-758c-4348-bb3e-8c777aa39728",
      "metadata": {
        "id": "3fc93d99-758c-4348-bb3e-8c777aa39728"
      },
      "source": [
        "Change our model to use a 5 × 5 kernel with kernel_size=5 passed to the nn.Conv2d constructor. <br>\n",
        "a What impact does this change have on the number of parameters in the model?<br>\n",
        "b Does the change improve or degrade overfitting?<br>\n",
        "c Read https://pytorch.org/docs/stable/nn.html#conv2d.<br>\n",
        "d Can you describe what kernel_size=(1,3) will do?<br>\n",
        "e How does the model behave with such a kernel?<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef56940c-c18c-4a06-b538-b2b0727a68d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef56940c-c18c-4a06-b538-b2b0727a68d0",
        "outputId": "c0620811-1916-4b2b-f84c-21c334dc11f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e6c98299a90>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da650d2f-60a5-4029-94b2-905866f7618a",
      "metadata": {
        "id": "da650d2f-60a5-4029-94b2-905866f7618a"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec5b048c-0cb4-4b6e-8dc5-d3d0c7760423",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec5b048c-0cb4-4b6e-8dc5-d3d0c7760423",
        "outputId": "196d8932-0588-43cc-a92b-de1e0cd9c20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 60942676.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data-unversioned/p1ch6/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c34ffa-3664-475a-8f57-cca15cb0138a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5c34ffa-3664-475a-8f57-cca15cb0138a",
        "outputId": "89c26a6d-d1f1-4577-870d-ff32ffb694cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d7cf5a6-df01-43eb-b317-54ce8cd6f01f",
      "metadata": {
        "id": "6d7cf5a6-df01-43eb-b317-54ce8cd6f01f"
      },
      "outputs": [],
      "source": [
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10\n",
        "          if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0, 2]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71c13b95-de9b-47b7-a016-f405cd0d6b53",
      "metadata": {
        "id": "71c13b95-de9b-47b7-a016-f405cd0d6b53"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The formula given for calculating the output size (one dimension) of a convolution is (W−F+2P)/S+1\n",
        "\n",
        "If you want to keep the output size same as the input size, you can equate (W−max(F,S)+2P)/S+1=W\n",
        "Solving this, when S=1\n",
        " gives:\n",
        "\n",
        "W−F+2P+1=W\n",
        "\n",
        "2P=F−1\n",
        "\n",
        "When S>1\n",
        ", you could solve the amount of padding needed to keep the output size same as the input size:\n",
        "\n",
        "2P=max(F,S)−S\n",
        "\n",
        "https://stats.stackexchange.com/questions/297678/how-to-calculate-optimal-zero-padding-for-convolutional-neural-networks"
      ],
      "metadata": {
        "id": "1MfTKAhylMkJ"
      },
      "id": "1MfTKAhylMkJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089f677d-8037-4a47-81c2-d2c7a3bc1ffd",
      "metadata": {
        "id": "089f677d-8037-4a47-81c2-d2c7a3bc1ffd"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5187844-403e-4852-ab8b-23608f7ca2bb",
      "metadata": {
        "id": "f5187844-403e-4852-ab8b-23608f7ca2bb"
      },
      "source": [
        "Number of Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd1d2a48-5d7f-4ddd-98e9-8d757aa4c264",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd1d2a48-5d7f-4ddd-98e9-8d757aa4c264",
        "outputId": "5155e4cc-b5f6-4004-9ef7-52171fb9a4bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20906, [1200, 16, 3200, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model = Net()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac398c6-5560-4f14-a4e0-574b1b936dce",
      "metadata": {
        "id": "fac398c6-5560-4f14-a4e0-574b1b936dce"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "497e3bda-b356-4b43-a82f-c0c622e246d1",
      "metadata": {
        "id": "497e3bda-b356-4b43-a82f-c0c622e246d1"
      },
      "outputs": [],
      "source": [
        "import datetime  # <1>\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "\n",
        "            outputs = model(imgs)  # <4>\n",
        "\n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "\n",
        "            loss.backward()  # <7>\n",
        "\n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the Dataset from chapter 7; wrap it into a DataLoader; instantiate our network, an optimizer, and a loss function as before; and call our training loop.\n",
        " The substantial changes in our model from the last chapter are that now our\n",
        "model is a custom subclass of nn.Module and that we’re using convolutions. Let’s run\n",
        "training for 100 epochs while printing the loss. Depending on your hardware, this\n",
        "may take 20 minutes or more to finish!"
      ],
      "metadata": {
        "id": "l7jWG1A3c_fi"
      },
      "id": "l7jWG1A3c_fi"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net()  #  <2>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItjS8PF5cvck",
        "outputId": "a48c2a15-60bb-4bb4-f100-6a0597b1ed18"
      },
      "id": "ItjS8PF5cvck",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-26 17:51:44.178096 Epoch 1, Training loss 0.5639230434302311\n",
            "2024-04-26 17:52:37.200346 Epoch 10, Training loss 0.3269234761880462\n",
            "2024-04-26 17:53:35.923911 Epoch 20, Training loss 0.2844390675520441\n",
            "2024-04-26 17:54:34.117760 Epoch 30, Training loss 0.2556565905072887\n",
            "2024-04-26 17:55:33.628358 Epoch 40, Training loss 0.2317938423555368\n",
            "2024-04-26 17:56:31.910825 Epoch 50, Training loss 0.2051310299118613\n",
            "2024-04-26 17:57:30.688470 Epoch 60, Training loss 0.18354635097228797\n",
            "2024-04-26 17:58:29.351167 Epoch 70, Training loss 0.1645348866464226\n",
            "2024-04-26 17:59:28.720147 Epoch 80, Training loss 0.14300961151814004\n",
            "2024-04-26 18:00:27.506357 Epoch 90, Training loss 0.12541566530515433\n",
            "2024-04-26 18:01:26.332072 Epoch 100, Training loss 0.10656613130478343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking Training and Validation Loss to see the amount of overfitting"
      ],
      "metadata": {
        "id": "6SFNaP_HeBxq"
      },
      "id": "6SFNaP_HeBxq"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "UI6L8LiGmY7L",
        "outputId": "f081af52-0730-48b7-b70d-a3454f7e4bfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UI6L8LiGmY7L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.96\n",
            "Accuracy val: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel_size can be a tuple of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension\n",
        "\n",
        "There is a slight increase in the training accuracy but no change in Validation accuracy when we change filter size from 3x3 to 5x5"
      ],
      "metadata": {
        "id": "t-pYqzgjmb08"
      },
      "id": "t-pYqzgjmb08"
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Kernel size (1,3) using padding = 'same' which pads the input so the output has the shape as the input. However, this mode doesn’t support any stride values other than 1."
      ],
      "metadata": {
        "id": "1NqUZRivW6Gw"
      },
      "id": "1NqUZRivW6Gw"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(1,3), padding='same')\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=(1,3), padding='same')\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "p18tNak-njXK"
      },
      "id": "p18tNak-njXK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "metadata": {
        "id": "yJ1BjjjXMw9h",
        "outputId": "c82daea4-7665-49a2-8a15-55ff6aac8a08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yJ1BjjjXMw9h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17034, [144, 16, 384, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime  # <1>\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "\n",
        "            outputs = model(imgs)  # <4>\n",
        "\n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "\n",
        "            loss.backward()  # <7>\n",
        "\n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ],
      "metadata": {
        "id": "AziqeAiZNGwz"
      },
      "id": "AziqeAiZNGwz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net()  #  <2>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "id": "wbBiyu84NNoa",
        "outputId": "9f76590c-bbfb-4dbc-a028-86c6a0a42619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wbBiyu84NNoa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-26 21:26:11.400002 Epoch 1, Training loss 0.5659798695023652\n",
            "2024-04-26 21:26:50.290938 Epoch 10, Training loss 0.34299551254245125\n",
            "2024-04-26 21:27:31.790345 Epoch 20, Training loss 0.3158297742817812\n",
            "2024-04-26 21:28:13.024979 Epoch 30, Training loss 0.2944501834880015\n",
            "2024-04-26 21:28:55.054121 Epoch 40, Training loss 0.27680306620658585\n",
            "2024-04-26 21:29:36.148278 Epoch 50, Training loss 0.2629637216116972\n",
            "2024-04-26 21:30:17.983434 Epoch 60, Training loss 0.24467909226941456\n",
            "2024-04-26 21:30:58.740232 Epoch 70, Training loss 0.23126557146667676\n",
            "2024-04-26 21:31:40.665242 Epoch 80, Training loss 0.21842472611149405\n",
            "2024-04-26 21:32:22.553775 Epoch 90, Training loss 0.20714929903958254\n",
            "2024-04-26 21:33:04.600887 Epoch 100, Training loss 0.19390393776973341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "T2S9O6aRNRiI",
        "outputId": "f72bf4bf-fa95-44de-84a6-0f9d7e4464e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T2S9O6aRNRiI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.92\n",
            "Accuracy val: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chap 10 Deep Learning with Python"
      ],
      "metadata": {
        "id": "WPAaLqS9sx5Q"
      },
      "id": "WPAaLqS9sx5Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 1: Load and prepare the weather data and implement the model described in\n",
        "Listing 10.23 (two GRU layers). <br>\n",
        "Replace the model-check-point callback with an early-stopping callback;  <br>\n",
        "set the restore_best_weights parameter to True and the patience parameter to 5.  <br>\n",
        "Monitor the validation MAE."
      ],
      "metadata": {
        "id": "Of-TsTC5Wzyd"
      },
      "id": "Of-TsTC5Wzyd"
    },
    {
      "cell_type": "code",
      "source": [
        "#loading and preparing the weather data\n",
        "!wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
        "!unzip jena_climate_2009_2016.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jkZm524N8im",
        "outputId": "93ab8fb0-8e6f-425e-9add-7c71776702b1"
      },
      "id": "0jkZm524N8im",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-27 15:44:06--  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.216.112, 52.216.134.29, 52.216.250.238, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.216.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13565642 (13M) [application/zip]\n",
            "Saving to: ‘jena_climate_2009_2016.csv.zip’\n",
            "\n",
            "jena_climate_2009_2 100%[===================>]  12.94M  41.2MB/s    in 0.3s    \n",
            "\n",
            "2024-04-27 15:44:07 (41.2 MB/s) - ‘jena_climate_2009_2016.csv.zip’ saved [13565642/13565642]\n",
            "\n",
            "Archive:  jena_climate_2009_2016.csv.zip\n",
            "  inflating: jena_climate_2009_2016.csv  \n",
            "  inflating: __MACOSX/._jena_climate_2009_2016.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecting the data of the Jena weather dataset"
      ],
      "metadata": {
        "id": "0SBr8OBHOvAM"
      },
      "id": "0SBr8OBHOvAM"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "fname = os.path.join(\"jena_climate_2009_2016.csv\")\n",
        "\n",
        "with open(fname) as f:\n",
        "    data = f.read()\n",
        "\n",
        "lines = data.split(\"\\n\")\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "print(header)\n",
        "print(len(lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0uFxe8fOkBh",
        "outputId": "b4d7ffe7-ce89-44db-b97a-fcb99dcbc9b8"
      },
      "id": "q0uFxe8fOkBh",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
            "420451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing the data"
      ],
      "metadata": {
        "id": "RrYUwnauO_N2"
      },
      "id": "RrYUwnauO_N2"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "temperature = np.zeros((len(lines),))\n",
        "raw_data = np.zeros((len(lines), len(header) - 1))\n",
        "for i, line in enumerate(lines):\n",
        "    values = [float(x) for x in line.split(\",\")[1:]]\n",
        "    temperature[i] = values[1]\n",
        "    raw_data[i, :] = values[:]"
      ],
      "metadata": {
        "id": "cpINoKikPNPY"
      },
      "id": "cpINoKikPNPY",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparing the data"
      ],
      "metadata": {
        "id": "SrUIbzJ2PPox"
      },
      "id": "SrUIbzJ2PPox"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the number of samples we'll use for each data split"
      ],
      "metadata": {
        "id": "1nK3VGMdPpzw"
      },
      "id": "1nK3VGMdPpzw"
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_samples = int(0.5 * len(raw_data))\n",
        "num_val_samples = int(0.25 * len(raw_data))\n",
        "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
        "print(\"num_train_samples:\", num_train_samples)\n",
        "print(\"num_val_samples:\", num_val_samples)\n",
        "print(\"num_test_samples:\", num_test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyyeXQ1oPujX",
        "outputId": "b9510914-dca0-41b1-9dfb-7413410fc456"
      },
      "id": "KyyeXQ1oPujX",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_train_samples: 210225\n",
            "num_val_samples: 105112\n",
            "num_test_samples: 105114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing the data"
      ],
      "metadata": {
        "id": "9U4VFYT6P2Fg"
      },
      "id": "9U4VFYT6P2Fg"
    },
    {
      "cell_type": "code",
      "source": [
        "mean = raw_data[:num_train_samples].mean(axis=0)\n",
        "raw_data -= mean\n",
        "std = raw_data[:num_train_samples].std(axis=0)\n",
        "raw_data /= std"
      ],
      "metadata": {
        "id": "3ucRuBADPdtv"
      },
      "id": "3ucRuBADPdtv",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiating datasets for training, validation, and testing"
      ],
      "metadata": {
        "id": "LmI4QM8PPgsq"
      },
      "id": "LmI4QM8PPgsq"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "sampling_rate = 6\n",
        "sequence_length = 120\n",
        "delay = sampling_rate * (sequence_length + 24 - 1)\n",
        "batch_size = 256\n",
        "\n",
        "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=0,\n",
        "    end_index=num_train_samples)\n",
        "\n",
        "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples,\n",
        "    end_index=num_train_samples + num_val_samples)\n",
        "\n",
        "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples + num_val_samples)"
      ],
      "metadata": {
        "id": "zGdth5UeQHUg"
      },
      "id": "zGdth5UeQHUg",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the common-sense baseline MAE"
      ],
      "metadata": {
        "id": "srULJlXtQN3Z"
      },
      "id": "srULJlXtQN3Z"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_naive_method(dataset):\n",
        "    total_abs_err = 0.\n",
        "    samples_seen = 0\n",
        "    for samples, targets in dataset:\n",
        "        preds = samples[:, -1, 1] * std[1] + mean[1]\n",
        "        total_abs_err += np.sum(np.abs(preds - targets))\n",
        "        samples_seen += samples.shape[0]\n",
        "    return total_abs_err / samples_seen\n",
        "\n",
        "print(f\"Validation MAE: {evaluate_naive_method(val_dataset):.2f}\")\n",
        "print(f\"Test MAE: {evaluate_naive_method(test_dataset):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMIPmansQ83I",
        "outputId": "2c035bc3-bc8e-4444-d0cf-591e480a2704"
      },
      "id": "hMIPmansQ83I",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MAE: 2.44\n",
            "Test MAE: 2.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stacking recurrent layers"
      ],
      "metadata": {
        "id": "31fhaccaQ_Ir"
      },
      "id": "31fhaccaQ_Ir"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Training and evaluating a dropout-regularized, stacked GRU model**<br>\n",
        "**Experiment 1**<br>\n",
        "Replace the model-check-point callback with an early-stopping callback; set the restore_best_weights parameter to True and the patience\n",
        "parameter to 5. Monitor the validation MAE."
      ],
      "metadata": {
        "id": "ItyncZNqRhRE"
      },
      "id": "ItyncZNqRhRE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "EarlyStopping : Stop training when a monitored metric has stopped improving.<br>\n",
        "<br>To stack recurrent layers on top of each other in Keras, all intermediate layers should return their full sequence of outputs (a rank-3 tensor) rather than their output at the last\n",
        "timestep. this is done by specifying return_sequences=True.\n",
        ""
      ],
      "metadata": {
        "id": "yd8af5uyT3DX"
      },
      "id": "yd8af5uyT3DX"
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(32, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(32, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping( monitor=\"val_mae\",patience=5,restore_best_weights=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj6W6vK_RwJP",
        "outputId": "d42e8abb-8cbd-4e94-eb61-248f088c9c17"
      },
      "id": "Cj6W6vK_RwJP",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "819/819 [==============================] - 187s 225ms/step - loss: 28.2655 - mae: 3.9035 - val_loss: 9.2553 - val_mae: 2.3457\n",
            "Epoch 2/50\n",
            "819/819 [==============================] - 191s 233ms/step - loss: 14.0323 - mae: 2.9054 - val_loss: 9.2471 - val_mae: 2.3594\n",
            "Epoch 3/50\n",
            "819/819 [==============================] - 189s 231ms/step - loss: 13.2106 - mae: 2.8194 - val_loss: 9.3891 - val_mae: 2.3792\n",
            "Epoch 4/50\n",
            "819/819 [==============================] - 189s 230ms/step - loss: 12.7239 - mae: 2.7673 - val_loss: 9.0997 - val_mae: 2.3381\n",
            "Epoch 5/50\n",
            "819/819 [==============================] - 187s 229ms/step - loss: 12.1535 - mae: 2.7027 - val_loss: 8.8078 - val_mae: 2.3117\n",
            "Epoch 6/50\n",
            "819/819 [==============================] - 189s 231ms/step - loss: 11.7367 - mae: 2.6605 - val_loss: 9.4152 - val_mae: 2.3940\n",
            "Epoch 7/50\n",
            "819/819 [==============================] - 187s 229ms/step - loss: 11.4010 - mae: 2.6232 - val_loss: 8.9971 - val_mae: 2.3470\n",
            "Epoch 8/50\n",
            "819/819 [==============================] - 187s 228ms/step - loss: 11.0140 - mae: 2.5779 - val_loss: 8.8801 - val_mae: 2.3162\n",
            "Epoch 9/50\n",
            "819/819 [==============================] - 191s 233ms/step - loss: 10.6830 - mae: 2.5395 - val_loss: 8.9042 - val_mae: 2.3328\n",
            "Epoch 10/50\n",
            "819/819 [==============================] - 190s 232ms/step - loss: 10.3618 - mae: 2.5016 - val_loss: 8.7669 - val_mae: 2.3098\n",
            "Epoch 11/50\n",
            "819/819 [==============================] - 187s 229ms/step - loss: 10.1401 - mae: 2.4756 - val_loss: 8.9031 - val_mae: 2.3277\n",
            "Epoch 12/50\n",
            "819/819 [==============================] - 192s 235ms/step - loss: 9.8808 - mae: 2.4459 - val_loss: 9.3397 - val_mae: 2.3929\n",
            "Epoch 13/50\n",
            "819/819 [==============================] - 194s 236ms/step - loss: 9.6811 - mae: 2.4204 - val_loss: 10.2499 - val_mae: 2.5060\n",
            "Epoch 14/50\n",
            "819/819 [==============================] - 196s 240ms/step - loss: 9.4684 - mae: 2.3928 - val_loss: 10.0537 - val_mae: 2.4785\n",
            "Epoch 15/50\n",
            "819/819 [==============================] - 195s 238ms/step - loss: 9.3022 - mae: 2.3730 - val_loss: 10.2053 - val_mae: 2.4894\n",
            "405/405 [==============================] - 27s 66ms/step - loss: 9.7947 - mae: 2.4723\n",
            "Test MAE: 2.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss = history.history[\"mae\"]\n",
        "val_loss = history.history[\"val_mae\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
        "plt.title(\"Training and validation MAE\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h55ZKrGCt4W5",
        "outputId": "a016f00b-0301-4afe-c3f7-61a154e61298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "id": "h55ZKrGCt4W5",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Increasing network capacity <br>\n",
        "Increasing network capacity is typically done by increasing the number of units in the layers or adding more layers.<br>\n",
        "####  Experiment 2: Adjust the number of units in each recurrent layer in the stacked setup, as well as the amount of dropout <br>\n",
        "<br>units: Positive integer, dimensionality of the output space.\n",
        "<br>unroll: Boolean (default: False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences."
      ],
      "metadata": {
        "id": "Y-m43R3pVE0W"
      },
      "id": "Y-m43R3pVE0W"
    },
    {
      "cell_type": "code",
      "source": [
        "# changing number of units to 64\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(64, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(64, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "id": "YCoZHOy2sKys",
        "outputId": "8adfe6be-b208-4cff-f13a-aa0389085be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "YCoZHOy2sKys",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "819/819 [==============================] - 350s 421ms/step - loss: 16.5783 - mae: 3.0800 - val_loss: 9.6551 - val_mae: 2.4197\n",
            "Epoch 2/50\n",
            "819/819 [==============================] - 370s 451ms/step - loss: 11.5364 - mae: 2.6465 - val_loss: 8.8680 - val_mae: 2.3134\n",
            "Epoch 3/50\n",
            "819/819 [==============================] - 355s 434ms/step - loss: 10.6332 - mae: 2.5452 - val_loss: 8.7056 - val_mae: 2.2834\n",
            "Epoch 4/50\n",
            "819/819 [==============================] - 363s 443ms/step - loss: 9.8686 - mae: 2.4485 - val_loss: 9.3124 - val_mae: 2.3699\n",
            "Epoch 5/50\n",
            "819/819 [==============================] - 351s 429ms/step - loss: 9.1792 - mae: 2.3586 - val_loss: 9.5232 - val_mae: 2.3987\n",
            "Epoch 6/50\n",
            "819/819 [==============================] - 358s 437ms/step - loss: 8.5697 - mae: 2.2773 - val_loss: 9.8860 - val_mae: 2.4407\n",
            "Epoch 7/50\n",
            "819/819 [==============================] - 351s 429ms/step - loss: 8.0451 - mae: 2.2013 - val_loss: 10.4823 - val_mae: 2.5260\n",
            "Epoch 8/50\n",
            "819/819 [==============================] - 366s 447ms/step - loss: 7.5844 - mae: 2.1371 - val_loss: 10.4036 - val_mae: 2.5158\n",
            "Epoch 9/50\n",
            "819/819 [==============================] - 363s 443ms/step - loss: 7.1903 - mae: 2.0808 - val_loss: 11.0494 - val_mae: 2.5945\n",
            "Epoch 10/50\n",
            "819/819 [==============================] - 340s 415ms/step - loss: 6.8602 - mae: 2.0306 - val_loss: 11.3184 - val_mae: 2.6288\n",
            "Epoch 11/50\n",
            "819/819 [==============================] - 396s 483ms/step - loss: 6.5524 - mae: 1.9833 - val_loss: 11.2781 - val_mae: 2.6198\n",
            "Epoch 12/50\n",
            "819/819 [==============================] - 375s 457ms/step - loss: 6.2884 - mae: 1.9421 - val_loss: 11.2775 - val_mae: 2.6215\n",
            "Epoch 13/50\n",
            "819/819 [==============================] - 339s 413ms/step - loss: 6.0357 - mae: 1.9034 - val_loss: 11.5460 - val_mae: 2.6584\n",
            "Epoch 14/50\n",
            "819/819 [==============================] - 336s 410ms/step - loss: 5.8681 - mae: 1.8769 - val_loss: 11.5888 - val_mae: 2.6682\n",
            "Epoch 15/50\n",
            "819/819 [==============================] - 362s 442ms/step - loss: 5.6752 - mae: 1.8445 - val_loss: 12.1974 - val_mae: 2.7250\n",
            "Epoch 16/50\n",
            "819/819 [==============================] - 347s 424ms/step - loss: 5.5417 - mae: 1.8220 - val_loss: 12.1333 - val_mae: 2.7253\n",
            "Epoch 17/50\n",
            "819/819 [==============================] - 344s 420ms/step - loss: 5.3911 - mae: 1.7975 - val_loss: 11.7979 - val_mae: 2.6796\n",
            "Epoch 18/50\n",
            "819/819 [==============================] - 338s 412ms/step - loss: 5.2440 - mae: 1.7760 - val_loss: 11.9287 - val_mae: 2.6955\n",
            "Epoch 19/50\n",
            "819/819 [==============================] - 339s 414ms/step - loss: 5.1593 - mae: 1.7590 - val_loss: 11.8304 - val_mae: 2.6836\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a200da81f9ec>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m history = model.fit(train_dataset,\n\u001b[0m\u001b[1;32m     15\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1793\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m         \"\"\"Resets the state of all the metrics in the model.\n\u001b[1;32m   2705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uy1z4whMy7KA"
      },
      "id": "Uy1z4whMy7KA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}