{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3fc93d99-758c-4348-bb3e-8c777aa39728",
      "metadata": {
        "id": "3fc93d99-758c-4348-bb3e-8c777aa39728"
      },
      "source": [
        "Change our model to use a 5 × 5 kernel with kernel_size=5 passed to the nn.Conv2d constructor. <br>\n",
        "a What impact does this change have on the number of parameters in the model?<br>\n",
        "b Does the change improve or degrade overfitting?<br>\n",
        "c Read https://pytorch.org/docs/stable/nn.html#conv2d.<br>\n",
        "d Can you describe what kernel_size=(1,3) will do?<br>\n",
        "e How does the model behave with such a kernel?<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef56940c-c18c-4a06-b538-b2b0727a68d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef56940c-c18c-4a06-b538-b2b0727a68d0",
        "outputId": "c0620811-1916-4b2b-f84c-21c334dc11f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e6c98299a90>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da650d2f-60a5-4029-94b2-905866f7618a",
      "metadata": {
        "id": "da650d2f-60a5-4029-94b2-905866f7618a"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec5b048c-0cb4-4b6e-8dc5-d3d0c7760423",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec5b048c-0cb4-4b6e-8dc5-d3d0c7760423",
        "outputId": "196d8932-0588-43cc-a92b-de1e0cd9c20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 60942676.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data-unversioned/p1ch6/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c34ffa-3664-475a-8f57-cca15cb0138a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5c34ffa-3664-475a-8f57-cca15cb0138a",
        "outputId": "89c26a6d-d1f1-4577-870d-ff32ffb694cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d7cf5a6-df01-43eb-b317-54ce8cd6f01f",
      "metadata": {
        "id": "6d7cf5a6-df01-43eb-b317-54ce8cd6f01f"
      },
      "outputs": [],
      "source": [
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10\n",
        "          if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0, 2]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71c13b95-de9b-47b7-a016-f405cd0d6b53",
      "metadata": {
        "id": "71c13b95-de9b-47b7-a016-f405cd0d6b53"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The formula given for calculating the output size (one dimension) of a convolution is (W−F+2P)/S+1\n",
        "\n",
        "If you want to keep the output size same as the input size, you can equate (W−max(F,S)+2P)/S+1=W\n",
        "Solving this, when S=1\n",
        " gives:\n",
        "\n",
        "W−F+2P+1=W\n",
        "\n",
        "2P=F−1\n",
        "\n",
        "When S>1\n",
        ", you could solve the amount of padding needed to keep the output size same as the input size:\n",
        "\n",
        "2P=max(F,S)−S\n",
        "\n",
        "https://stats.stackexchange.com/questions/297678/how-to-calculate-optimal-zero-padding-for-convolutional-neural-networks"
      ],
      "metadata": {
        "id": "1MfTKAhylMkJ"
      },
      "id": "1MfTKAhylMkJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089f677d-8037-4a47-81c2-d2c7a3bc1ffd",
      "metadata": {
        "id": "089f677d-8037-4a47-81c2-d2c7a3bc1ffd"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5187844-403e-4852-ab8b-23608f7ca2bb",
      "metadata": {
        "id": "f5187844-403e-4852-ab8b-23608f7ca2bb"
      },
      "source": [
        "Number of Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd1d2a48-5d7f-4ddd-98e9-8d757aa4c264",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd1d2a48-5d7f-4ddd-98e9-8d757aa4c264",
        "outputId": "5155e4cc-b5f6-4004-9ef7-52171fb9a4bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20906, [1200, 16, 3200, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model = Net()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac398c6-5560-4f14-a4e0-574b1b936dce",
      "metadata": {
        "id": "fac398c6-5560-4f14-a4e0-574b1b936dce"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "497e3bda-b356-4b43-a82f-c0c622e246d1",
      "metadata": {
        "id": "497e3bda-b356-4b43-a82f-c0c622e246d1"
      },
      "outputs": [],
      "source": [
        "import datetime  # <1>\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "\n",
        "            outputs = model(imgs)  # <4>\n",
        "\n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "\n",
        "            loss.backward()  # <7>\n",
        "\n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the Dataset from chapter 7; wrap it into a DataLoader; instantiate our network, an optimizer, and a loss function as before; and call our training loop.\n",
        " The substantial changes in our model from the last chapter are that now our\n",
        "model is a custom subclass of nn.Module and that we’re using convolutions. Let’s run\n",
        "training for 100 epochs while printing the loss. Depending on your hardware, this\n",
        "may take 20 minutes or more to finish!"
      ],
      "metadata": {
        "id": "l7jWG1A3c_fi"
      },
      "id": "l7jWG1A3c_fi"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net()  #  <2>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItjS8PF5cvck",
        "outputId": "a48c2a15-60bb-4bb4-f100-6a0597b1ed18"
      },
      "id": "ItjS8PF5cvck",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-26 17:51:44.178096 Epoch 1, Training loss 0.5639230434302311\n",
            "2024-04-26 17:52:37.200346 Epoch 10, Training loss 0.3269234761880462\n",
            "2024-04-26 17:53:35.923911 Epoch 20, Training loss 0.2844390675520441\n",
            "2024-04-26 17:54:34.117760 Epoch 30, Training loss 0.2556565905072887\n",
            "2024-04-26 17:55:33.628358 Epoch 40, Training loss 0.2317938423555368\n",
            "2024-04-26 17:56:31.910825 Epoch 50, Training loss 0.2051310299118613\n",
            "2024-04-26 17:57:30.688470 Epoch 60, Training loss 0.18354635097228797\n",
            "2024-04-26 17:58:29.351167 Epoch 70, Training loss 0.1645348866464226\n",
            "2024-04-26 17:59:28.720147 Epoch 80, Training loss 0.14300961151814004\n",
            "2024-04-26 18:00:27.506357 Epoch 90, Training loss 0.12541566530515433\n",
            "2024-04-26 18:01:26.332072 Epoch 100, Training loss 0.10656613130478343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking Training and Validation Loss to see the amount of overfitting"
      ],
      "metadata": {
        "id": "6SFNaP_HeBxq"
      },
      "id": "6SFNaP_HeBxq"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "UI6L8LiGmY7L",
        "outputId": "f081af52-0730-48b7-b70d-a3454f7e4bfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UI6L8LiGmY7L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.96\n",
            "Accuracy val: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel_size can be a tuple of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension\n",
        "\n",
        "There is a slight increase in the training accuracy but no change in Validation accuracy when we change filter size from 3x3 to 5x5"
      ],
      "metadata": {
        "id": "t-pYqzgjmb08"
      },
      "id": "t-pYqzgjmb08"
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Kernel size (1,3) using padding = 'same' which pads the input so the output has the shape as the input. However, this mode doesn’t support any stride values other than 1."
      ],
      "metadata": {
        "id": "1NqUZRivW6Gw"
      },
      "id": "1NqUZRivW6Gw"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(1,3), padding='same')\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=(1,3), padding='same')\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "p18tNak-njXK"
      },
      "id": "p18tNak-njXK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "metadata": {
        "id": "yJ1BjjjXMw9h",
        "outputId": "c82daea4-7665-49a2-8a15-55ff6aac8a08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yJ1BjjjXMw9h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17034, [144, 16, 384, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime  # <1>\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "\n",
        "            outputs = model(imgs)  # <4>\n",
        "\n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "\n",
        "            loss.backward()  # <7>\n",
        "\n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ],
      "metadata": {
        "id": "AziqeAiZNGwz"
      },
      "id": "AziqeAiZNGwz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net()  #  <2>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "id": "wbBiyu84NNoa",
        "outputId": "9f76590c-bbfb-4dbc-a028-86c6a0a42619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wbBiyu84NNoa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-26 21:26:11.400002 Epoch 1, Training loss 0.5659798695023652\n",
            "2024-04-26 21:26:50.290938 Epoch 10, Training loss 0.34299551254245125\n",
            "2024-04-26 21:27:31.790345 Epoch 20, Training loss 0.3158297742817812\n",
            "2024-04-26 21:28:13.024979 Epoch 30, Training loss 0.2944501834880015\n",
            "2024-04-26 21:28:55.054121 Epoch 40, Training loss 0.27680306620658585\n",
            "2024-04-26 21:29:36.148278 Epoch 50, Training loss 0.2629637216116972\n",
            "2024-04-26 21:30:17.983434 Epoch 60, Training loss 0.24467909226941456\n",
            "2024-04-26 21:30:58.740232 Epoch 70, Training loss 0.23126557146667676\n",
            "2024-04-26 21:31:40.665242 Epoch 80, Training loss 0.21842472611149405\n",
            "2024-04-26 21:32:22.553775 Epoch 90, Training loss 0.20714929903958254\n",
            "2024-04-26 21:33:04.600887 Epoch 100, Training loss 0.19390393776973341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "T2S9O6aRNRiI",
        "outputId": "f72bf4bf-fa95-44de-84a6-0f9d7e4464e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T2S9O6aRNRiI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.92\n",
            "Accuracy val: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chap 10 Deep Learning with Python"
      ],
      "metadata": {
        "id": "WPAaLqS9sx5Q"
      },
      "id": "WPAaLqS9sx5Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 1: Load and prepare the weather data and implement the model described in\n",
        "Listing 10.23 (two GRU layers). <br>\n",
        "Replace the model-check-point callback with an early-stopping callback;  <br>\n",
        "set the restore_best_weights parameter to True and the patience parameter to 5.  <br>\n",
        "Monitor the validation MAE."
      ],
      "metadata": {
        "id": "Of-TsTC5Wzyd"
      },
      "id": "Of-TsTC5Wzyd"
    },
    {
      "cell_type": "code",
      "source": [
        "#loading and preparing the weather data\n",
        "!wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
        "!unzip jena_climate_2009_2016.csv.zip"
      ],
      "metadata": {
        "id": "0jkZm524N8im",
        "outputId": "a9dfe92b-bee3-4d0b-e2ad-0d05d19bee59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0jkZm524N8im",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-27 20:50:01--  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.147.37, 52.217.136.184, 54.231.230.24, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.147.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13565642 (13M) [application/zip]\n",
            "Saving to: ‘jena_climate_2009_2016.csv.zip.1’\n",
            "\n",
            "jena_climate_2009_2 100%[===================>]  12.94M  44.8MB/s    in 0.3s    \n",
            "\n",
            "2024-04-27 20:50:02 (44.8 MB/s) - ‘jena_climate_2009_2016.csv.zip.1’ saved [13565642/13565642]\n",
            "\n",
            "Archive:  jena_climate_2009_2016.csv.zip\n",
            "replace jena_climate_2009_2016.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecting the data of the Jena weather dataset"
      ],
      "metadata": {
        "id": "0SBr8OBHOvAM"
      },
      "id": "0SBr8OBHOvAM"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "fname = os.path.join(\"jena_climate_2009_2016.csv\")\n",
        "\n",
        "with open(fname) as f:\n",
        "    data = f.read()\n",
        "\n",
        "lines = data.split(\"\\n\")\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "print(header)\n",
        "print(len(lines))"
      ],
      "metadata": {
        "id": "q0uFxe8fOkBh",
        "outputId": "c7627dc5-ed61-47d6-c91a-c26cd37bfe56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "q0uFxe8fOkBh",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
            "420451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing the data"
      ],
      "metadata": {
        "id": "RrYUwnauO_N2"
      },
      "id": "RrYUwnauO_N2"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "temperature = np.zeros((len(lines),))\n",
        "raw_data = np.zeros((len(lines), len(header) - 1))\n",
        "for i, line in enumerate(lines):\n",
        "    values = [float(x) for x in line.split(\",\")[1:]]\n",
        "    temperature[i] = values[1]\n",
        "    raw_data[i, :] = values[:]"
      ],
      "metadata": {
        "id": "cpINoKikPNPY"
      },
      "id": "cpINoKikPNPY",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparing the data"
      ],
      "metadata": {
        "id": "SrUIbzJ2PPox"
      },
      "id": "SrUIbzJ2PPox"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the number of samples we'll use for each data split"
      ],
      "metadata": {
        "id": "1nK3VGMdPpzw"
      },
      "id": "1nK3VGMdPpzw"
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_samples = int(0.5 * len(raw_data))\n",
        "num_val_samples = int(0.25 * len(raw_data))\n",
        "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
        "print(\"num_train_samples:\", num_train_samples)\n",
        "print(\"num_val_samples:\", num_val_samples)\n",
        "print(\"num_test_samples:\", num_test_samples)"
      ],
      "metadata": {
        "id": "KyyeXQ1oPujX",
        "outputId": "d89527ed-d797-4c29-8fb9-6c8fda96f5ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KyyeXQ1oPujX",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_train_samples: 210225\n",
            "num_val_samples: 105112\n",
            "num_test_samples: 105114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing the data"
      ],
      "metadata": {
        "id": "9U4VFYT6P2Fg"
      },
      "id": "9U4VFYT6P2Fg"
    },
    {
      "cell_type": "code",
      "source": [
        "mean = raw_data[:num_train_samples].mean(axis=0)\n",
        "raw_data -= mean\n",
        "std = raw_data[:num_train_samples].std(axis=0)\n",
        "raw_data /= std"
      ],
      "metadata": {
        "id": "3ucRuBADPdtv"
      },
      "id": "3ucRuBADPdtv",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiating datasets for training, validation, and testing"
      ],
      "metadata": {
        "id": "LmI4QM8PPgsq"
      },
      "id": "LmI4QM8PPgsq"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "sampling_rate = 6\n",
        "sequence_length = 120\n",
        "delay = sampling_rate * (sequence_length + 24 - 1)\n",
        "batch_size = 256\n",
        "\n",
        "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=0,\n",
        "    end_index=num_train_samples)\n",
        "\n",
        "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples,\n",
        "    end_index=num_train_samples + num_val_samples)\n",
        "\n",
        "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples + num_val_samples)"
      ],
      "metadata": {
        "id": "zGdth5UeQHUg"
      },
      "id": "zGdth5UeQHUg",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the common-sense baseline MAE"
      ],
      "metadata": {
        "id": "srULJlXtQN3Z"
      },
      "id": "srULJlXtQN3Z"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_naive_method(dataset):\n",
        "    total_abs_err = 0.\n",
        "    samples_seen = 0\n",
        "    for samples, targets in dataset:\n",
        "        preds = samples[:, -1, 1] * std[1] + mean[1]\n",
        "        total_abs_err += np.sum(np.abs(preds - targets))\n",
        "        samples_seen += samples.shape[0]\n",
        "    return total_abs_err / samples_seen\n",
        "\n",
        "print(f\"Validation MAE: {evaluate_naive_method(val_dataset):.2f}\")\n",
        "print(f\"Test MAE: {evaluate_naive_method(test_dataset):.2f}\")"
      ],
      "metadata": {
        "id": "hMIPmansQ83I",
        "outputId": "a9bdad2d-5891-4e04-aaa5-3707f8be14f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hMIPmansQ83I",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MAE: 2.44\n",
            "Test MAE: 2.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stacking recurrent layers"
      ],
      "metadata": {
        "id": "31fhaccaQ_Ir"
      },
      "id": "31fhaccaQ_Ir"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Training and evaluating a dropout-regularized, stacked GRU model**<br>\n",
        "**Experiment 1**<br>\n",
        "Replace the model-check-point callback with an early-stopping callback; set the restore_best_weights parameter to True and the patience\n",
        "parameter to 5. Monitor the validation MAE."
      ],
      "metadata": {
        "id": "ItyncZNqRhRE"
      },
      "id": "ItyncZNqRhRE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "EarlyStopping : Stop training when a monitored metric has stopped improving.<br>\n",
        "<br> Test_mae value greater than the original GRU model after changing to early stopping. Original GRU model has 2.39 as test_mae value"
      ],
      "metadata": {
        "id": "yd8af5uyT3DX"
      },
      "id": "yd8af5uyT3DX"
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(32, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(32, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping( monitor=\"val_mae\",patience=5,restore_best_weights=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "id": "Cj6W6vK_RwJP",
        "outputId": "d42e8abb-8cbd-4e94-eb61-248f088c9c17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Cj6W6vK_RwJP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "819/819 [==============================] - 187s 225ms/step - loss: 28.2655 - mae: 3.9035 - val_loss: 9.2553 - val_mae: 2.3457\n",
            "Epoch 2/50\n",
            "819/819 [==============================] - 191s 233ms/step - loss: 14.0323 - mae: 2.9054 - val_loss: 9.2471 - val_mae: 2.3594\n",
            "Epoch 3/50\n",
            "819/819 [==============================] - 189s 231ms/step - loss: 13.2106 - mae: 2.8194 - val_loss: 9.3891 - val_mae: 2.3792\n",
            "Epoch 4/50\n",
            "819/819 [==============================] - 189s 230ms/step - loss: 12.7239 - mae: 2.7673 - val_loss: 9.0997 - val_mae: 2.3381\n",
            "Epoch 5/50\n",
            "819/819 [==============================] - 187s 229ms/step - loss: 12.1535 - mae: 2.7027 - val_loss: 8.8078 - val_mae: 2.3117\n",
            "Epoch 6/50\n",
            "819/819 [==============================] - 189s 231ms/step - loss: 11.7367 - mae: 2.6605 - val_loss: 9.4152 - val_mae: 2.3940\n",
            "Epoch 7/50\n",
            "819/819 [==============================] - 187s 229ms/step - loss: 11.4010 - mae: 2.6232 - val_loss: 8.9971 - val_mae: 2.3470\n",
            "Epoch 8/50\n",
            "819/819 [==============================] - 187s 228ms/step - loss: 11.0140 - mae: 2.5779 - val_loss: 8.8801 - val_mae: 2.3162\n",
            "Epoch 9/50\n",
            "819/819 [==============================] - 191s 233ms/step - loss: 10.6830 - mae: 2.5395 - val_loss: 8.9042 - val_mae: 2.3328\n",
            "Epoch 10/50\n",
            "819/819 [==============================] - 190s 232ms/step - loss: 10.3618 - mae: 2.5016 - val_loss: 8.7669 - val_mae: 2.3098\n",
            "Epoch 11/50\n",
            "819/819 [==============================] - 187s 229ms/step - loss: 10.1401 - mae: 2.4756 - val_loss: 8.9031 - val_mae: 2.3277\n",
            "Epoch 12/50\n",
            "819/819 [==============================] - 192s 235ms/step - loss: 9.8808 - mae: 2.4459 - val_loss: 9.3397 - val_mae: 2.3929\n",
            "Epoch 13/50\n",
            "819/819 [==============================] - 194s 236ms/step - loss: 9.6811 - mae: 2.4204 - val_loss: 10.2499 - val_mae: 2.5060\n",
            "Epoch 14/50\n",
            "819/819 [==============================] - 196s 240ms/step - loss: 9.4684 - mae: 2.3928 - val_loss: 10.0537 - val_mae: 2.4785\n",
            "Epoch 15/50\n",
            "819/819 [==============================] - 195s 238ms/step - loss: 9.3022 - mae: 2.3730 - val_loss: 10.2053 - val_mae: 2.4894\n",
            "405/405 [==============================] - 27s 66ms/step - loss: 9.7947 - mae: 2.4723\n",
            "Test MAE: 2.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Experiment 2: Adjust the number of units in each recurrent layer in the stacked setup, as well as the amount of dropout\n",
        "\n",
        "units: Positive integer, dimensionality of the output space.<br>\n",
        "units changed to 16 and recurrent_dropout and dropout changed to 0.3<br>\n",
        "Observation: Test_mae value greater than the original GRU model and no significant change from Experiment 1.<br>\n"
      ],
      "metadata": {
        "id": "Y-m43R3pVE0W"
      },
      "id": "Y-m43R3pVE0W"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(16, recurrent_dropout=0.3, return_sequences=True)(inputs)\n",
        "x = layers.GRU(16, recurrent_dropout=0.3)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYHwAa0_TBkh",
        "outputId": "1bb0671d-ab06-41f7-925b-b3e0c665ad03"
      },
      "id": "RYHwAa0_TBkh",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "819/819 [==============================] - 159s 189ms/step - loss: 39.8764 - mae: 4.6351 - val_loss: 12.2673 - val_mae: 2.6216\n",
            "Epoch 2/50\n",
            "819/819 [==============================] - 139s 169ms/step - loss: 14.3318 - mae: 2.9289 - val_loss: 9.1999 - val_mae: 2.3433\n",
            "Epoch 3/50\n",
            "819/819 [==============================] - 139s 170ms/step - loss: 13.0486 - mae: 2.8040 - val_loss: 9.0523 - val_mae: 2.3318\n",
            "Epoch 4/50\n",
            "819/819 [==============================] - 140s 171ms/step - loss: 12.5551 - mae: 2.7477 - val_loss: 8.9762 - val_mae: 2.3191\n",
            "Epoch 5/50\n",
            "819/819 [==============================] - 144s 175ms/step - loss: 12.1766 - mae: 2.7072 - val_loss: 9.0265 - val_mae: 2.3324\n",
            "Epoch 6/50\n",
            "819/819 [==============================] - 148s 181ms/step - loss: 11.8159 - mae: 2.6697 - val_loss: 8.6915 - val_mae: 2.2958\n",
            "Epoch 7/50\n",
            "819/819 [==============================] - 146s 178ms/step - loss: 11.5321 - mae: 2.6405 - val_loss: 8.9875 - val_mae: 2.3314\n",
            "Epoch 8/50\n",
            "819/819 [==============================] - 147s 179ms/step - loss: 11.2034 - mae: 2.6013 - val_loss: 9.1916 - val_mae: 2.3591\n",
            "Epoch 9/50\n",
            "819/819 [==============================] - 142s 173ms/step - loss: 10.9345 - mae: 2.5721 - val_loss: 9.0894 - val_mae: 2.3555\n",
            "Epoch 10/50\n",
            "819/819 [==============================] - 141s 172ms/step - loss: 10.7431 - mae: 2.5524 - val_loss: 8.8944 - val_mae: 2.3296\n",
            "Epoch 11/50\n",
            "819/819 [==============================] - 140s 171ms/step - loss: 10.4935 - mae: 2.5241 - val_loss: 8.8584 - val_mae: 2.3235\n",
            "Epoch 12/50\n",
            "819/819 [==============================] - 140s 171ms/step - loss: 10.3815 - mae: 2.5089 - val_loss: 8.8087 - val_mae: 2.3102\n",
            "Epoch 13/50\n",
            "819/819 [==============================] - 139s 170ms/step - loss: 10.2358 - mae: 2.4919 - val_loss: 9.2268 - val_mae: 2.3715\n",
            "Epoch 14/50\n",
            "819/819 [==============================] - 140s 171ms/step - loss: 10.1041 - mae: 2.4778 - val_loss: 9.3117 - val_mae: 2.3895\n",
            "Epoch 15/50\n",
            "819/819 [==============================] - 138s 168ms/step - loss: 9.9811 - mae: 2.4629 - val_loss: 9.3547 - val_mae: 2.3866\n",
            "Epoch 16/50\n",
            "819/819 [==============================] - 138s 169ms/step - loss: 9.8687 - mae: 2.4486 - val_loss: 9.3020 - val_mae: 2.3847\n",
            "Epoch 17/50\n",
            "819/819 [==============================] - 138s 168ms/step - loss: 9.7777 - mae: 2.4369 - val_loss: 9.4296 - val_mae: 2.4049\n",
            "Epoch 18/50\n",
            "819/819 [==============================] - 138s 168ms/step - loss: 9.6559 - mae: 2.4212 - val_loss: 9.6074 - val_mae: 2.4192\n",
            "Epoch 19/50\n",
            "819/819 [==============================] - 139s 169ms/step - loss: 9.5908 - mae: 2.4148 - val_loss: 9.8707 - val_mae: 2.4556\n",
            "Epoch 20/50\n",
            "819/819 [==============================] - 140s 171ms/step - loss: 9.4829 - mae: 2.4021 - val_loss: 9.7845 - val_mae: 2.4537\n",
            "Epoch 21/50\n",
            "819/819 [==============================] - 139s 169ms/step - loss: 9.3638 - mae: 2.3878 - val_loss: 10.1913 - val_mae: 2.4996\n",
            "Epoch 22/50\n",
            "819/819 [==============================] - 140s 170ms/step - loss: 9.3320 - mae: 2.3831 - val_loss: 10.1360 - val_mae: 2.4920\n",
            "Epoch 23/50\n",
            "819/819 [==============================] - 141s 172ms/step - loss: 9.2289 - mae: 2.3692 - val_loss: 10.4250 - val_mae: 2.5195\n",
            "Epoch 24/50\n",
            "819/819 [==============================] - 142s 173ms/step - loss: 9.2057 - mae: 2.3681 - val_loss: 10.1650 - val_mae: 2.4880\n",
            "Epoch 25/50\n",
            "819/819 [==============================] - 144s 176ms/step - loss: 9.1154 - mae: 2.3559 - val_loss: 10.4241 - val_mae: 2.5217\n",
            "Epoch 26/50\n",
            "819/819 [==============================] - 144s 176ms/step - loss: 9.0864 - mae: 2.3537 - val_loss: 10.6803 - val_mae: 2.5506\n",
            "Epoch 27/50\n",
            "819/819 [==============================] - 144s 175ms/step - loss: 8.9841 - mae: 2.3365 - val_loss: 10.2161 - val_mae: 2.4966\n",
            "Epoch 28/50\n",
            "819/819 [==============================] - 151s 184ms/step - loss: 8.9278 - mae: 2.3323 - val_loss: 10.6990 - val_mae: 2.5543\n",
            "Epoch 29/50\n",
            "819/819 [==============================] - 151s 185ms/step - loss: 8.8786 - mae: 2.3263 - val_loss: 10.5162 - val_mae: 2.5280\n",
            "Epoch 30/50\n",
            "819/819 [==============================] - 146s 177ms/step - loss: 8.8267 - mae: 2.3199 - val_loss: 10.6955 - val_mae: 2.5515\n",
            "Epoch 31/50\n",
            "819/819 [==============================] - 150s 183ms/step - loss: 8.7318 - mae: 2.3072 - val_loss: 10.7344 - val_mae: 2.5575\n",
            "Epoch 32/50\n",
            "819/819 [==============================] - 145s 177ms/step - loss: 8.6886 - mae: 2.3015 - val_loss: 10.8880 - val_mae: 2.5779\n",
            "Epoch 33/50\n",
            "819/819 [==============================] - 173s 211ms/step - loss: 8.6433 - mae: 2.2952 - val_loss: 11.0735 - val_mae: 2.5972\n",
            "Epoch 34/50\n",
            "819/819 [==============================] - 148s 180ms/step - loss: 8.5993 - mae: 2.2907 - val_loss: 11.0310 - val_mae: 2.5901\n",
            "Epoch 35/50\n",
            "819/819 [==============================] - 143s 175ms/step - loss: 8.5863 - mae: 2.2858 - val_loss: 11.0411 - val_mae: 2.5940\n",
            "Epoch 36/50\n",
            "819/819 [==============================] - 145s 177ms/step - loss: 8.5590 - mae: 2.2835 - val_loss: 11.0833 - val_mae: 2.5999\n",
            "Epoch 37/50\n",
            "819/819 [==============================] - 145s 176ms/step - loss: 8.4990 - mae: 2.2756 - val_loss: 11.1924 - val_mae: 2.6217\n",
            "Epoch 38/50\n",
            "819/819 [==============================] - 163s 199ms/step - loss: 8.4449 - mae: 2.2687 - val_loss: 11.6336 - val_mae: 2.6691\n",
            "Epoch 39/50\n",
            "819/819 [==============================] - 141s 172ms/step - loss: 8.4052 - mae: 2.2637 - val_loss: 11.2441 - val_mae: 2.6187\n",
            "Epoch 40/50\n",
            "819/819 [==============================] - 140s 170ms/step - loss: 8.4070 - mae: 2.2644 - val_loss: 11.5902 - val_mae: 2.6694\n",
            "Epoch 41/50\n",
            "819/819 [==============================] - 139s 170ms/step - loss: 8.3665 - mae: 2.2574 - val_loss: 11.4612 - val_mae: 2.6519\n",
            "Epoch 42/50\n",
            "819/819 [==============================] - 138s 169ms/step - loss: 8.3112 - mae: 2.2520 - val_loss: 11.5068 - val_mae: 2.6581\n",
            "Epoch 43/50\n",
            "819/819 [==============================] - 138s 169ms/step - loss: 8.2856 - mae: 2.2474 - val_loss: 11.4078 - val_mae: 2.6445\n",
            "Epoch 44/50\n",
            "819/819 [==============================] - 142s 173ms/step - loss: 8.2436 - mae: 2.2426 - val_loss: 11.5805 - val_mae: 2.6577\n",
            "Epoch 45/50\n",
            "819/819 [==============================] - 143s 174ms/step - loss: 8.2647 - mae: 2.2449 - val_loss: 11.3945 - val_mae: 2.6416\n",
            "Epoch 46/50\n",
            "819/819 [==============================] - 144s 176ms/step - loss: 8.2135 - mae: 2.2372 - val_loss: 11.5788 - val_mae: 2.6578\n",
            "Epoch 47/50\n",
            "819/819 [==============================] - 141s 172ms/step - loss: 8.2110 - mae: 2.2364 - val_loss: 11.9130 - val_mae: 2.7076\n",
            "Epoch 48/50\n",
            "819/819 [==============================] - 140s 171ms/step - loss: 8.1554 - mae: 2.2310 - val_loss: 11.5887 - val_mae: 2.6674\n",
            "Epoch 49/50\n",
            "819/819 [==============================] - 140s 171ms/step - loss: 8.1476 - mae: 2.2295 - val_loss: 11.5778 - val_mae: 2.6613\n",
            "Epoch 50/50\n",
            "819/819 [==============================] - 139s 170ms/step - loss: 8.1245 - mae: 2.2249 - val_loss: 11.8192 - val_mae: 2.6908\n",
            "405/405 [==============================] - 21s 49ms/step - loss: 9.7268 - mae: 2.4484\n",
            "Test MAE: 2.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Experiment 3: Adjust the learning rate used by the RMSprop optimizer, or try a\n",
        "different optimizer, e.g., Adam."
      ],
      "metadata": {
        "id": "m7BpnG8ITnYj"
      },
      "id": "m7BpnG8ITnYj"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(16, recurrent_dropout=0.3, return_sequences=True)(inputs)\n",
        "x = layers.GRU(16, recurrent_dropout=0.3)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuccP-Ot6IPj",
        "outputId": "1871accc-f7c8-4efe-b1c3-55b92d510daf"
      },
      "id": "AuccP-Ot6IPj",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "819/819 [==============================] - 154s 183ms/step - loss: 46.2343 - mae: 4.9966 - val_loss: 18.6787 - val_mae: 3.1482\n",
            "Epoch 2/50\n",
            "819/819 [==============================] - 153s 186ms/step - loss: 17.4435 - mae: 3.1564 - val_loss: 11.6887 - val_mae: 2.5635\n",
            "Epoch 3/50\n",
            "819/819 [==============================] - 153s 187ms/step - loss: 14.3600 - mae: 2.9117 - val_loss: 10.3212 - val_mae: 2.4500\n",
            "Epoch 4/50\n",
            "819/819 [==============================] - 152s 185ms/step - loss: 13.3287 - mae: 2.8201 - val_loss: 9.8207 - val_mae: 2.4097\n",
            "Epoch 5/50\n",
            "819/819 [==============================] - 153s 187ms/step - loss: 12.7641 - mae: 2.7632 - val_loss: 9.5004 - val_mae: 2.3844\n",
            "Epoch 6/50\n",
            "819/819 [==============================] - 152s 185ms/step - loss: 12.4051 - mae: 2.7269 - val_loss: 9.8322 - val_mae: 2.4328\n",
            "Epoch 7/50\n",
            "819/819 [==============================] - 149s 182ms/step - loss: 12.0690 - mae: 2.6920 - val_loss: 9.2135 - val_mae: 2.3590\n",
            "Epoch 8/50\n",
            "819/819 [==============================] - 148s 181ms/step - loss: 11.6992 - mae: 2.6520 - val_loss: 9.3870 - val_mae: 2.3778\n",
            "Epoch 9/50\n",
            "819/819 [==============================] - 146s 178ms/step - loss: 11.3975 - mae: 2.6184 - val_loss: 9.4680 - val_mae: 2.3926\n",
            "Epoch 10/50\n",
            "819/819 [==============================] - 146s 178ms/step - loss: 11.1267 - mae: 2.5914 - val_loss: 9.4907 - val_mae: 2.3934\n",
            "Epoch 11/50\n",
            "819/819 [==============================] - 151s 185ms/step - loss: 10.8956 - mae: 2.5649 - val_loss: 9.1921 - val_mae: 2.3614\n",
            "Epoch 12/50\n",
            "819/819 [==============================] - 152s 185ms/step - loss: 10.7788 - mae: 2.5500 - val_loss: 9.2109 - val_mae: 2.3637\n",
            "Epoch 13/50\n",
            "819/819 [==============================] - 148s 180ms/step - loss: 10.4964 - mae: 2.5187 - val_loss: 9.2424 - val_mae: 2.3674\n",
            "Epoch 14/50\n",
            "819/819 [==============================] - 149s 182ms/step - loss: 10.3483 - mae: 2.5029 - val_loss: 9.5171 - val_mae: 2.4066\n",
            "Epoch 15/50\n",
            "819/819 [==============================] - 145s 177ms/step - loss: 10.1762 - mae: 2.4790 - val_loss: 9.4418 - val_mae: 2.3977\n",
            "Epoch 16/50\n",
            "819/819 [==============================] - 145s 177ms/step - loss: 10.0679 - mae: 2.4681 - val_loss: 9.5398 - val_mae: 2.4126\n",
            "Epoch 17/50\n",
            "819/819 [==============================] - 146s 177ms/step - loss: 9.8823 - mae: 2.4481 - val_loss: 9.4202 - val_mae: 2.3942\n",
            "Epoch 18/50\n",
            "819/819 [==============================] - 148s 181ms/step - loss: 9.8184 - mae: 2.4362 - val_loss: 9.5816 - val_mae: 2.4241\n",
            "Epoch 19/50\n",
            "819/819 [==============================] - 146s 178ms/step - loss: 9.6819 - mae: 2.4231 - val_loss: 9.6322 - val_mae: 2.4271\n",
            "Epoch 20/50\n",
            "819/819 [==============================] - 146s 178ms/step - loss: 9.5998 - mae: 2.4127 - val_loss: 9.5757 - val_mae: 2.4219\n",
            "Epoch 21/50\n",
            "819/819 [==============================] - 145s 177ms/step - loss: 9.5204 - mae: 2.4024 - val_loss: 9.8807 - val_mae: 2.4657\n",
            "Epoch 22/50\n",
            "819/819 [==============================] - 145s 177ms/step - loss: 9.5698 - mae: 2.4078 - val_loss: 9.8016 - val_mae: 2.4546\n",
            "Epoch 23/50\n",
            "819/819 [==============================] - 146s 177ms/step - loss: 9.4002 - mae: 2.3849 - val_loss: 10.0165 - val_mae: 2.4820\n",
            "Epoch 24/50\n",
            "819/819 [==============================] - 143s 174ms/step - loss: 9.3849 - mae: 2.3833 - val_loss: 10.0013 - val_mae: 2.4781\n",
            "Epoch 25/50\n",
            "819/819 [==============================] - 143s 175ms/step - loss: 9.2711 - mae: 2.3702 - val_loss: 9.8288 - val_mae: 2.4589\n",
            "Epoch 26/50\n",
            "819/819 [==============================] - 146s 178ms/step - loss: 9.2326 - mae: 2.3650 - val_loss: 10.0724 - val_mae: 2.4889\n",
            "Epoch 27/50\n",
            "819/819 [==============================] - 142s 174ms/step - loss: 9.1498 - mae: 2.3577 - val_loss: 10.1472 - val_mae: 2.4989\n",
            "Epoch 28/50\n",
            "819/819 [==============================] - 143s 175ms/step - loss: 9.0871 - mae: 2.3494 - val_loss: 10.1992 - val_mae: 2.5060\n",
            "Epoch 29/50\n",
            "819/819 [==============================] - 157s 192ms/step - loss: 9.1002 - mae: 2.3490 - val_loss: 10.3365 - val_mae: 2.5237\n",
            "Epoch 30/50\n",
            "819/819 [==============================] - 159s 194ms/step - loss: 8.9996 - mae: 2.3357 - val_loss: 10.2972 - val_mae: 2.5142\n",
            "Epoch 31/50\n",
            "819/819 [==============================] - 173s 211ms/step - loss: 8.9954 - mae: 2.3382 - val_loss: 10.3981 - val_mae: 2.5343\n",
            "Epoch 32/50\n",
            "819/819 [==============================] - 158s 193ms/step - loss: 8.9255 - mae: 2.3250 - val_loss: 10.3388 - val_mae: 2.5196\n",
            "Epoch 33/50\n",
            "819/819 [==============================] - 153s 187ms/step - loss: 8.8893 - mae: 2.3238 - val_loss: 10.4818 - val_mae: 2.5411\n",
            "Epoch 34/50\n",
            "819/819 [==============================] - 147s 179ms/step - loss: 8.8405 - mae: 2.3176 - val_loss: 10.5426 - val_mae: 2.5468\n",
            "Epoch 35/50\n",
            "819/819 [==============================] - 145s 177ms/step - loss: 8.8017 - mae: 2.3099 - val_loss: 10.5666 - val_mae: 2.5541\n",
            "Epoch 36/50\n",
            "819/819 [==============================] - 151s 185ms/step - loss: 8.7320 - mae: 2.3002 - val_loss: 10.6353 - val_mae: 2.5598\n",
            "Epoch 37/50\n",
            "819/819 [==============================] - 152s 185ms/step - loss: 8.6460 - mae: 2.2938 - val_loss: 10.9288 - val_mae: 2.6010\n",
            "Epoch 38/50\n",
            "819/819 [==============================] - 153s 187ms/step - loss: 8.6576 - mae: 2.2900 - val_loss: 10.8512 - val_mae: 2.5928\n",
            "Epoch 39/50\n",
            "819/819 [==============================] - 151s 184ms/step - loss: 8.6158 - mae: 2.2891 - val_loss: 10.7980 - val_mae: 2.5790\n",
            "Epoch 40/50\n",
            "819/819 [==============================] - 147s 179ms/step - loss: 8.6087 - mae: 2.2837 - val_loss: 10.9294 - val_mae: 2.6037\n",
            "Epoch 41/50\n",
            "819/819 [==============================] - 147s 179ms/step - loss: 8.5374 - mae: 2.2782 - val_loss: 10.9612 - val_mae: 2.6021\n",
            "Epoch 42/50\n",
            "819/819 [==============================] - 157s 192ms/step - loss: 8.5152 - mae: 2.2737 - val_loss: 10.9081 - val_mae: 2.5962\n",
            "Epoch 43/50\n",
            "819/819 [==============================] - 158s 192ms/step - loss: 8.4610 - mae: 2.2669 - val_loss: 11.1965 - val_mae: 2.6272\n",
            "Epoch 44/50\n",
            "819/819 [==============================] - 146s 178ms/step - loss: 8.4428 - mae: 2.2678 - val_loss: 11.1109 - val_mae: 2.6194\n",
            "Epoch 45/50\n",
            "819/819 [==============================] - 154s 187ms/step - loss: 8.4088 - mae: 2.2623 - val_loss: 11.0075 - val_mae: 2.6062\n",
            "Epoch 46/50\n",
            "819/819 [==============================] - 154s 187ms/step - loss: 8.3748 - mae: 2.2546 - val_loss: 11.2889 - val_mae: 2.6440\n",
            "Epoch 47/50\n",
            "819/819 [==============================] - 144s 176ms/step - loss: 8.3494 - mae: 2.2535 - val_loss: 11.1616 - val_mae: 2.6226\n",
            "Epoch 48/50\n",
            "819/819 [==============================] - 148s 181ms/step - loss: 8.3304 - mae: 2.2518 - val_loss: 11.2669 - val_mae: 2.6368\n",
            "Epoch 49/50\n",
            "819/819 [==============================] - 148s 180ms/step - loss: 8.3143 - mae: 2.2475 - val_loss: 11.0575 - val_mae: 2.6071\n",
            "Epoch 50/50\n",
            "819/819 [==============================] - 149s 181ms/step - loss: 8.2691 - mae: 2.2407 - val_loss: 11.3101 - val_mae: 2.6398\n",
            "405/405 [==============================] - 20s 47ms/step - loss: 9.9412 - mae: 2.4845\n",
            "Test MAE: 2.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W0H_S13c2xpz"
      },
      "id": "W0H_S13c2xpz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Experiment 4: Try using a stack of Dense layers as the regressor on top of the recurrent layer, instead of a single Dense layer."
      ],
      "metadata": {
        "id": "ME2_oGr08L-j"
      },
      "id": "ME2_oGr08L-j"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(32, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(32, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(16)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(8)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping( monitor=\"val_mae\",patience=5,restore_best_weights=True)\n",
        "]\n",
        "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=25,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbaHUOBHdmhn",
        "outputId": "f2ca9690-39ad-4519-931a-362f41abd261"
      },
      "id": "zbaHUOBHdmhn",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "819/819 [==============================] - 204s 241ms/step - loss: 44.9574 - mae: 5.0454 - val_loss: 12.8786 - val_mae: 2.7985\n",
            "Epoch 2/25\n",
            "819/819 [==============================] - 195s 237ms/step - loss: 33.4972 - mae: 4.3675 - val_loss: 13.1244 - val_mae: 2.8335\n",
            "Epoch 3/25\n",
            "819/819 [==============================] - 195s 238ms/step - loss: 30.6107 - mae: 4.1887 - val_loss: 12.0087 - val_mae: 2.7181\n",
            "Epoch 4/25\n",
            "819/819 [==============================] - 190s 232ms/step - loss: 28.9354 - mae: 4.0811 - val_loss: 11.0847 - val_mae: 2.5975\n",
            "Epoch 5/25\n",
            "819/819 [==============================] - 185s 226ms/step - loss: 27.5296 - mae: 3.9826 - val_loss: 11.6425 - val_mae: 2.6663\n",
            "Epoch 6/25\n",
            "819/819 [==============================] - 187s 228ms/step - loss: 26.4273 - mae: 3.9021 - val_loss: 10.8786 - val_mae: 2.5678\n",
            "Epoch 7/25\n",
            "819/819 [==============================] - 190s 231ms/step - loss: 25.5345 - mae: 3.8341 - val_loss: 10.6083 - val_mae: 2.5346\n",
            "Epoch 8/25\n",
            "819/819 [==============================] - 187s 228ms/step - loss: 24.5909 - mae: 3.7601 - val_loss: 11.9589 - val_mae: 2.6973\n",
            "Epoch 9/25\n",
            "819/819 [==============================] - 187s 228ms/step - loss: 23.8236 - mae: 3.7011 - val_loss: 11.6531 - val_mae: 2.6323\n",
            "Epoch 10/25\n",
            "819/819 [==============================] - 188s 229ms/step - loss: 23.0892 - mae: 3.6454 - val_loss: 11.5131 - val_mae: 2.6468\n",
            "Epoch 11/25\n",
            "819/819 [==============================] - 188s 229ms/step - loss: 22.7106 - mae: 3.6085 - val_loss: 11.1672 - val_mae: 2.6021\n",
            "Epoch 12/25\n",
            "819/819 [==============================] - 190s 231ms/step - loss: 22.3352 - mae: 3.5691 - val_loss: 10.6299 - val_mae: 2.5390\n",
            "405/405 [==============================] - 26s 62ms/step - loss: 12.2582 - mae: 2.7402\n",
            "Test MAE: 2.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Representation as Pandas Dataframe and Bar Chart"
      ],
      "metadata": {
        "id": "3vDq5La94TJN"
      },
      "id": "3vDq5La94TJN"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Data\n",
        "test_mae = [2.62, 2.39, 2.47, 2.45, 2.48, 2.74]\n",
        "val_mae = [2.44, 2.36, 2.48, 2.69, 2.63, 2.53]\n",
        "index = ['Baseline', 'Original_GRU', 'Expt1', 'Expt2', 'Expt3', 'Expt4']\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({'test_mae': test_mae, 'val_mae': val_mae}, index=index)\n",
        "\n",
        "# Display DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "rzpnbUwh4JLT",
        "outputId": "67911b6f-385f-4fe6-d6be-e06f7d229665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rzpnbUwh4JLT",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              test_mae  val_mae\n",
            "Baseline          2.62     2.44\n",
            "Original_GRU      2.39     2.36\n",
            "Expt1             2.47     2.48\n",
            "Expt2             2.45     2.69\n",
            "Expt3             2.48     2.63\n",
            "Expt4             2.74     2.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "test_mae= [2.62, 2.39, 2.47, 2.45, 2.48, 2.74]\n",
        "val_mae = [2.44, 2.36, 2.48, 2.69, 2.63, 2.53]\n",
        "index = ['Baseline','Original_GRU', 'Expt1', 'Expt2','Expt3', 'Expt4']\n",
        "df = pd.DataFrame({'test_mae': test_mae, 'val_mae': val_mae }, index=index)\n",
        "ax = df.plot.bar(rot=0)\n",
        "plt.legend(fontsize='small',loc='upper center')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RbcsbH61y9km",
        "outputId": "eaa1b1a7-2d84-4c6d-df85-fd2ecc5d43e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "id": "RbcsbH61y9km",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comprehensive Conclusion: <br>\n",
        "<br>\n",
        "The common-sense baseline achieves a validation MAE of 2.44 degrees Celsius and a test MAE of 2.62 degrees Celsius. So if we always assume that the temperature 24 hours in the future will be the same as it is now, we will be off by two and a half degrees on average.<br>\n",
        "<br>\n",
        "The Original GRU model achieves a test_mae of 2.39 degrees which is 8.8% improvement over the baseline<br>\n",
        "<br>\n",
        "Experiment 1 model achieves a test_mae of 2.47 degrees which is 5.7% improvement over the baseline<br>\n",
        "<br>\n",
        "Experiment 2 model achieves a test_mae of 2.45 degrees which is 6.5% improvement over the baseline<br>\n",
        "<br>\n",
        "Experiment 3 model achieves a test_mae of 2.48 degrees which is 5.3% improvement over the baseline<br>\n",
        "<br>\n",
        "Experiment 4 model achieves a test_mae of 2.74 degrees which is 4.6%\n",
        "degradation from the baseline<br>\n",
        "\n",
        "<br>\n",
        "Therefore, Original GRU model with two recurrent layers and one dense layer achieves the best performance out of the other four models."
      ],
      "metadata": {
        "id": "uiKdKQbdm4NC"
      },
      "id": "uiKdKQbdm4NC"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oTgvo6bmrlOn"
      },
      "id": "oTgvo6bmrlOn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}