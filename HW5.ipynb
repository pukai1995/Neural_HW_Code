{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3fc93d99-758c-4348-bb3e-8c777aa39728",
      "metadata": {
        "id": "3fc93d99-758c-4348-bb3e-8c777aa39728"
      },
      "source": [
        "Change our model to use a 5 × 5 kernel with kernel_size=5 passed to the nn.Conv2d constructor. <br>\n",
        "a What impact does this change have on the number of parameters in the model?<br>\n",
        "b Does the change improve or degrade overfitting?<br>\n",
        "c Read https://pytorch.org/docs/stable/nn.html#conv2d.<br>\n",
        "d Can you describe what kernel_size=(1,3) will do?<br>\n",
        "e How does the model behave with such a kernel?<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ef56940c-c18c-4a06-b538-b2b0727a68d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef56940c-c18c-4a06-b538-b2b0727a68d0",
        "outputId": "c0620811-1916-4b2b-f84c-21c334dc11f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e6c98299a90>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "da650d2f-60a5-4029-94b2-905866f7618a",
      "metadata": {
        "id": "da650d2f-60a5-4029-94b2-905866f7618a"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ec5b048c-0cb4-4b6e-8dc5-d3d0c7760423",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec5b048c-0cb4-4b6e-8dc5-d3d0c7760423",
        "outputId": "196d8932-0588-43cc-a92b-de1e0cd9c20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 60942676.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data-unversioned/p1ch6/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a5c34ffa-3664-475a-8f57-cca15cb0138a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5c34ffa-3664-475a-8f57-cca15cb0138a",
        "outputId": "89c26a6d-d1f1-4577-870d-ff32ffb694cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6d7cf5a6-df01-43eb-b317-54ce8cd6f01f",
      "metadata": {
        "id": "6d7cf5a6-df01-43eb-b317-54ce8cd6f01f"
      },
      "outputs": [],
      "source": [
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10\n",
        "          if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0, 2]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71c13b95-de9b-47b7-a016-f405cd0d6b53",
      "metadata": {
        "id": "71c13b95-de9b-47b7-a016-f405cd0d6b53"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The formula given for calculating the output size (one dimension) of a convolution is (W−F+2P)/S+1\n",
        "\n",
        "If you want to keep the output size same as the input size, you can equate (W−max(F,S)+2P)/S+1=W\n",
        "Solving this, when S=1\n",
        " gives:\n",
        "\n",
        "W−F+2P+1=W\n",
        "\n",
        "2P=F−1\n",
        "\n",
        "When S>1\n",
        ", you could solve the amount of padding needed to keep the output size same as the input size:\n",
        "\n",
        "2P=max(F,S)−S\n",
        "\n",
        "https://stats.stackexchange.com/questions/297678/how-to-calculate-optimal-zero-padding-for-convolutional-neural-networks"
      ],
      "metadata": {
        "id": "1MfTKAhylMkJ"
      },
      "id": "1MfTKAhylMkJ"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "089f677d-8037-4a47-81c2-d2c7a3bc1ffd",
      "metadata": {
        "id": "089f677d-8037-4a47-81c2-d2c7a3bc1ffd"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5187844-403e-4852-ab8b-23608f7ca2bb",
      "metadata": {
        "id": "f5187844-403e-4852-ab8b-23608f7ca2bb"
      },
      "source": [
        "Number of Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "fd1d2a48-5d7f-4ddd-98e9-8d757aa4c264",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd1d2a48-5d7f-4ddd-98e9-8d757aa4c264",
        "outputId": "5155e4cc-b5f6-4004-9ef7-52171fb9a4bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20906, [1200, 16, 3200, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model = Net()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac398c6-5560-4f14-a4e0-574b1b936dce",
      "metadata": {
        "id": "fac398c6-5560-4f14-a4e0-574b1b936dce"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "497e3bda-b356-4b43-a82f-c0c622e246d1",
      "metadata": {
        "id": "497e3bda-b356-4b43-a82f-c0c622e246d1"
      },
      "outputs": [],
      "source": [
        "import datetime  # <1>\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "\n",
        "            outputs = model(imgs)  # <4>\n",
        "\n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "\n",
        "            loss.backward()  # <7>\n",
        "\n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the Dataset from chapter 7; wrap it into a DataLoader; instantiate our network, an optimizer, and a loss function as before; and call our training loop.\n",
        " The substantial changes in our model from the last chapter are that now our\n",
        "model is a custom subclass of nn.Module and that we’re using convolutions. Let’s run\n",
        "training for 100 epochs while printing the loss. Depending on your hardware, this\n",
        "may take 20 minutes or more to finish!"
      ],
      "metadata": {
        "id": "l7jWG1A3c_fi"
      },
      "id": "l7jWG1A3c_fi"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net()  #  <2>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItjS8PF5cvck",
        "outputId": "a48c2a15-60bb-4bb4-f100-6a0597b1ed18"
      },
      "id": "ItjS8PF5cvck",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-26 17:51:44.178096 Epoch 1, Training loss 0.5639230434302311\n",
            "2024-04-26 17:52:37.200346 Epoch 10, Training loss 0.3269234761880462\n",
            "2024-04-26 17:53:35.923911 Epoch 20, Training loss 0.2844390675520441\n",
            "2024-04-26 17:54:34.117760 Epoch 30, Training loss 0.2556565905072887\n",
            "2024-04-26 17:55:33.628358 Epoch 40, Training loss 0.2317938423555368\n",
            "2024-04-26 17:56:31.910825 Epoch 50, Training loss 0.2051310299118613\n",
            "2024-04-26 17:57:30.688470 Epoch 60, Training loss 0.18354635097228797\n",
            "2024-04-26 17:58:29.351167 Epoch 70, Training loss 0.1645348866464226\n",
            "2024-04-26 17:59:28.720147 Epoch 80, Training loss 0.14300961151814004\n",
            "2024-04-26 18:00:27.506357 Epoch 90, Training loss 0.12541566530515433\n",
            "2024-04-26 18:01:26.332072 Epoch 100, Training loss 0.10656613130478343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking Training and Validation Loss to see the amount of overfitting"
      ],
      "metadata": {
        "id": "6SFNaP_HeBxq"
      },
      "id": "6SFNaP_HeBxq"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "UI6L8LiGmY7L",
        "outputId": "f081af52-0730-48b7-b70d-a3454f7e4bfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UI6L8LiGmY7L",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.96\n",
            "Accuracy val: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel_size can be a tuple of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension\n",
        "\n",
        "There is a slight increase in the training accuracy but no change in Validation accuracy when we change filter size from 3x3 to 5x5"
      ],
      "metadata": {
        "id": "t-pYqzgjmb08"
      },
      "id": "t-pYqzgjmb08"
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Kernel size (1,3) using padding = 'same' which pads the input so the output has the shape as the input. However, this mode doesn’t support any stride values other than 1."
      ],
      "metadata": {
        "id": "1NqUZRivW6Gw"
      },
      "id": "1NqUZRivW6Gw"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(1,3), padding='same')\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=(1,3), padding='same')\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "p18tNak-njXK"
      },
      "id": "p18tNak-njXK",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "metadata": {
        "id": "yJ1BjjjXMw9h",
        "outputId": "c82daea4-7665-49a2-8a15-55ff6aac8a08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yJ1BjjjXMw9h",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17034, [144, 16, 384, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime  # <1>\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "\n",
        "            outputs = model(imgs)  # <4>\n",
        "\n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "\n",
        "            loss.backward()  # <7>\n",
        "\n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ],
      "metadata": {
        "id": "AziqeAiZNGwz"
      },
      "id": "AziqeAiZNGwz",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net()  #  <2>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "id": "wbBiyu84NNoa",
        "outputId": "9f76590c-bbfb-4dbc-a028-86c6a0a42619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wbBiyu84NNoa",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-26 21:26:11.400002 Epoch 1, Training loss 0.5659798695023652\n",
            "2024-04-26 21:26:50.290938 Epoch 10, Training loss 0.34299551254245125\n",
            "2024-04-26 21:27:31.790345 Epoch 20, Training loss 0.3158297742817812\n",
            "2024-04-26 21:28:13.024979 Epoch 30, Training loss 0.2944501834880015\n",
            "2024-04-26 21:28:55.054121 Epoch 40, Training loss 0.27680306620658585\n",
            "2024-04-26 21:29:36.148278 Epoch 50, Training loss 0.2629637216116972\n",
            "2024-04-26 21:30:17.983434 Epoch 60, Training loss 0.24467909226941456\n",
            "2024-04-26 21:30:58.740232 Epoch 70, Training loss 0.23126557146667676\n",
            "2024-04-26 21:31:40.665242 Epoch 80, Training loss 0.21842472611149405\n",
            "2024-04-26 21:32:22.553775 Epoch 90, Training loss 0.20714929903958254\n",
            "2024-04-26 21:33:04.600887 Epoch 100, Training loss 0.19390393776973341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "T2S9O6aRNRiI",
        "outputId": "f72bf4bf-fa95-44de-84a6-0f9d7e4464e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T2S9O6aRNRiI",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.92\n",
            "Accuracy val: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ECS9mLnWsyKb"
      },
      "id": "ECS9mLnWsyKb"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sH7tsKxCsyIc"
      },
      "id": "sH7tsKxCsyIc"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PzpFyOp9syGO"
      },
      "id": "PzpFyOp9syGO"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SKE3-L4-syDr"
      },
      "id": "SKE3-L4-syDr"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3dpwmFJNsyBD"
      },
      "id": "3dpwmFJNsyBD"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IA6TfQWQsx_M"
      },
      "id": "IA6TfQWQsx_M"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WPAaLqS9sx5Q"
      },
      "id": "WPAaLqS9sx5Q"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Of-TsTC5Wzyd"
      },
      "id": "Of-TsTC5Wzyd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}